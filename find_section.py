#!/usr/bin/env python3
"""
Section Finder for Website and PDF Extractors

This utility script helps Claude Code quickly find and display section information
from JSON files generated by the web_outline_extractor.py and pdf_outline_extractor.py tools.

Usage:
    python find_section.py "search term" --json-file headings.json
    python find_section.py "[2.1] Table of Contents" --json-file headings.json
    python find_section.py "character-stats" --json-file headings.json --by-id
"""

import json
import argparse
import sys
import re
from difflib import SequenceMatcher
from typing import List, Dict, Any, Optional


def load_json_file(file_path: str) -> Dict[str, Any]:
    """Load and parse JSON file."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Error: File '{file_path}' not found.")
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"Error: Invalid JSON in '{file_path}': {e}")
        sys.exit(1)


def normalize_search_term(term: str) -> str:
    """Normalize search term for comparison."""
    return term.lower().strip()


def extract_reference_key(term: str) -> Optional[str]:
    """Extract reference key from search term if present."""
    # Match patterns like [2.1], [1.3], etc.
    match = re.search(r'\[(\d+\.\d+)\]', term)
    if match:
        return match.group(1)
    return None


def calculate_similarity(text1: str, text2: str) -> float:
    """Calculate similarity between two strings."""
    return SequenceMatcher(None, text1.lower(), text2.lower()).ratio()


def search_by_reference_key(headings: List[Dict], reference_key: str) -> List[Dict]:
    """Search headings by reference key pattern."""
    matches = []
    pattern = f"[{reference_key}]"
    
    for heading in headings:
        heading_ref = heading.get('reference_key', '')
        if pattern in heading_ref:
            matches.append(heading)
    
    return matches


def search_by_title(headings: List[Dict], search_term: str, fuzzy: bool = False) -> List[Dict]:
    """Search headings by title."""
    matches = []
    normalized_term = normalize_search_term(search_term)
    
    # Remove reference key pattern from search term if present
    clean_term = re.sub(r'\[\d+\.\d+\]\s*', '', search_term).strip()
    normalized_clean = normalize_search_term(clean_term)
    
    for heading in headings:
        title = normalize_search_term(heading.get('title', ''))
        
        # Exact match
        if normalized_clean == title or normalized_term == title:
            matches.append({'heading': heading, 'score': 1.0, 'match_type': 'exact'})
            continue
        
        # Substring match
        if normalized_clean in title or normalized_term in title:
            matches.append({'heading': heading, 'score': 0.8, 'match_type': 'substring'})
            continue
        
        # Search variants
        variants = heading.get('search_variants', [])
        for variant in variants:
            if normalized_clean == variant or normalized_term == variant:
                matches.append({'heading': heading, 'score': 0.7, 'match_type': 'variant'})
                break
            elif normalized_clean in variant or normalized_term in variant:
                matches.append({'heading': heading, 'score': 0.6, 'match_type': 'variant_partial'})
                break
        
        # Fuzzy matching
        if fuzzy:
            title_similarity = calculate_similarity(normalized_clean, title)
            if title_similarity > 0.6:
                matches.append({'heading': heading, 'score': title_similarity, 'match_type': 'fuzzy'})
    
    # Sort by score (highest first)
    matches.sort(key=lambda x: x['score'], reverse=True)
    return [match['heading'] for match in matches]


def search_by_id(headings: List[Dict], element_id: str) -> List[Dict]:
    """Search headings by element ID."""
    matches = []
    normalized_id = element_id.lower().strip().lstrip('#')
    
    for heading in headings:
        heading_id = heading.get('id', '').lower()
        if normalized_id == heading_id:
            matches.append(heading)
    
    return matches


def search_headings(headings: List[Dict], search_term: str, by_id: bool = False, 
                   fuzzy: bool = False, all_matches: bool = False) -> List[Dict]:
    """Main search function."""
    matches = []
    
    # Check if search term contains a reference key
    reference_key = extract_reference_key(search_term)
    
    if by_id:
        matches = search_by_id(headings, search_term)
    elif reference_key:
        matches = search_by_reference_key(headings, reference_key)
    else:
        matches = search_by_title(headings, search_term, fuzzy)
    
    if not all_matches and matches:
        return [matches[0]]  # Return only the best match
    
    return matches


def format_hierarchical_path(path: List[str]) -> str:
    """Format hierarchical path for display."""
    if not path:
        return ""
    return " > ".join(path)


def display_heading(heading: Dict, show_content: bool = True, show_context: bool = False):
    """Display a single heading with formatting."""
    reference_key = heading.get('reference_key', '')
    title = heading.get('title', 'Untitled')
    level = heading.get('level', 0)
    tag = heading.get('tag', '')
    heading_id = heading.get('id', '')
    content = heading.get('content', '')
    page = heading.get('page')  # For PDF bookmarks
    path = heading.get('hierarchical_path', [])
    
    print(f"\n{'='*60}")
    print(f"Found: {reference_key}")
    print(f"Title: {title}")
    
    # Show different info for PDFs vs websites
    if page is not None:
        print(f"Level: {level} | Page: {page}")
    else:
        print(f"Level: {level} | Tag: {tag}")
        if heading_id:
            print(f"Element ID: {heading_id}")
    
    if show_context and path:
        print(f"Path: {format_hierarchical_path(path)}")
    
    if show_content:
        if content:
            print(f"\nContent preview:")
            print(f"{content}")
        elif page is not None:
            print(f"\nPage information: Page {page}")
    
    print(f"{'='*60}")


def find_related_sections(headings: List[Dict], target_heading: Dict) -> List[Dict]:
    """Find related sections (children and siblings)."""
    related = []
    target_level = target_heading.get('level', 0)
    target_path = target_heading.get('hierarchical_path', [])
    
    if not target_path:
        return related
    
    # Find immediate children (next level down with same parent path)
    target_parent_path = target_path[:-1]
    
    for heading in headings:
        heading_level = heading.get('level', 0)
        heading_path = heading.get('hierarchical_path', [])
        
        # Skip the target heading itself
        if heading.get('reference_key') == target_heading.get('reference_key'):
            continue
        
        # Find immediate children
        if (heading_level == target_level + 1 and 
            len(heading_path) > len(target_path) and 
            heading_path[:len(target_path)] == target_path):
            related.append(heading)
    
    return related


def main():
    parser = argparse.ArgumentParser(
        description='Find sections in website/PDF outline JSON files',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    python find_section.py "Table of Contents" --json-file headings.json
    python find_section.py "[2.1] Character Stats" --json-file headings.json
    python find_section.py "table-of-contents" --json-file headings.json --by-id
    python find_section.py "Combat" --json-file headings.json --all-matches
    python find_section.py "Charcter Stats" --json-file headings.json --fuzzy
        """
    )
    
    parser.add_argument('search_term', help='Text to search for (title, reference key, or ID)')
    parser.add_argument('--json-file', required=True, help='Path to JSON file to search')
    parser.add_argument('--by-id', action='store_true', help='Search by element ID')
    parser.add_argument('--fuzzy', action='store_true', help='Enable fuzzy matching for typos')
    parser.add_argument('--all-matches', action='store_true', help='Show all matching sections')
    parser.add_argument('--show-content', action='store_true', help='Display full content preview')
    parser.add_argument('--show-context', action='store_true', help='Show hierarchical context')
    parser.add_argument('--show-related', action='store_true', help='Show related sections (children)')
    
    args = parser.parse_args()
    
    # Load JSON data
    data = load_json_file(args.json_file)
    
    # Extract headings or bookmarks (support both formats)
    headings = data.get('headings', [])
    if not headings:
        headings = data.get('bookmarks', [])
    
    if not headings:
        print("No headings or bookmarks found in JSON file.")
        sys.exit(1)
    
    # Search for matches
    matches = search_headings(
        headings, 
        args.search_term, 
        by_id=args.by_id,
        fuzzy=args.fuzzy,
        all_matches=args.all_matches
    )
    
    if not matches:
        print(f"No matches found for: '{args.search_term}'")
        
        # Suggest similar matches if fuzzy wasn't enabled
        if not args.fuzzy:
            print("\nTry using --fuzzy for approximate matches, or --all-matches to see more results.")
            
            # Show a few potential matches
            fuzzy_matches = search_by_title(headings, args.search_term, fuzzy=True)[:3]
            if fuzzy_matches:
                print("\nDid you mean:")
                for i, match in enumerate(fuzzy_matches, 1):
                    ref_key = match.get('reference_key', '')
                    title = match.get('title', '')
                    print(f"  {i}. {ref_key} - {title}")
        
        sys.exit(1)
    
    # Display results
    if len(matches) == 1:
        print(f"Found 1 match for: '{args.search_term}'")
    else:
        print(f"Found {len(matches)} matches for: '{args.search_term}'")
    
    for i, heading in enumerate(matches):
        if i > 0:
            print("\n" + "-"*60)
        
        display_heading(
            heading, 
            show_content=args.show_content or len(matches) == 1,
            show_context=args.show_context
        )
        
        # Show related sections for single matches
        if args.show_related and len(matches) == 1:
            related = find_related_sections(headings, heading)
            if related:
                print(f"\nRelated sections ({len(related)} found):")
                for rel in related[:5]:  # Limit to 5 related sections
                    ref_key = rel.get('reference_key', '')
                    title = rel.get('title', '')
                    print(f"  • {ref_key} - {title}")
                if len(related) > 5:
                    print(f"  ... and {len(related) - 5} more")


if __name__ == "__main__":
    main()